# L_SPIDER
****
A spider with some methods that been used to crawling data like news and title or pic ,and another things which not encode in  Complex algorithmï¼ˆwell,the truth is i do not learn about it ,if someday i got it ,a new spider will been creat ,i promise.ï¼‰<br>
At very first i code this just for help my friend to finish thier subject , and by the way training my programing capacity<br>.
But more i try to improve and perfect ,more i astounded about pentent ablity of SPIDER.<br>
_Excellent data killerï¼Œyou can analyse anything by useing magic algorithm and your favourite programing language with the huge data you crawled by spider if web server allow.ğŸ˜ˆ_<br>
Why i don't use scrapy or another frame? very simple,caused easy task need no Rocket Launcherï¼Œisn't it? <br>
In other words, I want to make a wheel to play by myself.<br>
Wish my code would help you to save some worry like i assisted my friends,good luck with you,guy.ğŸ˜‡<br>
                                                                                                                                            __LOVEMOSTISBUG__<br>
è¿™æ˜¯ä¸€ä¸ªç”¨æ¥æŠ“å–æ•°æ®ï¼Œæ¯”å¦‚æ–°é—»ã€æ ‡é¢˜æˆ–å›¾ç‰‡ï¼Œè¿˜æœ‰ä¸€äº›æ²¡æœ‰ç”¨å¤æ‚çš„ç®—æ³•è¿›è¡Œç¼–ç çš„æ•°æ®çš„***å°çˆ¬è™«***ï¼ˆå¥½å§ï¼Œå…¶å®æ˜¯å°å¼Ÿ**å­¦ä¸šä¸ç²¾**ï¼Œå“ªå¤©æˆ‘æ‡‚äº†ï¼Œä¼šæŠŠè¯¥æœ‰çš„éƒ½åŠ ä¸Šå»çš„ï¼Œä¿è¯ï¼‰ã€‚<br>
ä¸€å¼€å§‹æˆ‘ç¼–å†™è¿™ä¸ªä»£ç åªæ˜¯ä¸ºäº†å¸®æˆ‘çš„æœ‹å‹å®Œæˆä»–ä»¬çš„è¯¾é¢˜ï¼Œé¡ºä¾¿è®­ç»ƒæˆ‘è‡ªå·±çš„ç¼–ç¨‹èƒ½åŠ›ã€‚<br>
ä½†è¶Šæ˜¯åŠ æ²¹æ”¹è¿›å’Œå®Œå–„ï¼Œå°±è¶ŠæƒŠè®¶äºçˆ¬è™«çš„æ½œèƒ½ã€‚<br>
_ç‰›Xçš„æ•°æ®æ€æ‰‹ï¼Œä½ å¯ä»¥åˆ†æä»»ä½•äº‹ç‰©é€šè¿‡ä½¿ç”¨é­”æœ¯ç®—æ³•å’Œä½ æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€ä¸ä½ çˆ¬ä¸‹æ¥çš„å·¨å¤§æ•°æ®ï¼Œ**å¦‚æœç½‘ç»œæœåŠ¡å™¨å…è®¸**ã€‚ğŸ˜ˆ_<br>
ä¸ºæ¯›æˆ‘ä¸ç”¨Scrapyè¿™æ ·çš„æ¡†æ¶å»çˆ¬ï¼Ÿæ€é¸¡ç„‰ç”¨ç‰›åˆ€ï¼Œä½ è¯´æ˜¯å§~<br>
è¿˜æœ‰çš„è¯å…¶å®æ˜¯æˆ‘ä¹Ÿæƒ³é€ ä¸ªè½®å­è‡ªå·±ç©ï¼ˆå°å£°bbï¼‰<br>
å¸Œæœ›æˆ‘çš„ä»£ç èƒ½å¸®ä½ çœå»ä¸€äº›çƒ¦æ¼ï¼Œå°±åƒæˆ‘å¸®åŠ©æˆ‘çš„æœ‹å‹ä¸€æ ·ï¼Œç¥ä½ å¥½è¿ï¼Œä¼™è®¡ã€‚ğŸ˜‡<br>
                                                                                                                                            __LOVEMOSTISBUG__  <br>
# How to crawl æ¸¸æˆå¼€å§‹
****
skip è·³è¿‡æ•™ç¨‹ 
****
## TASK 1 çˆ¬å–ç™¾åº¦è´´å§æŸä¸ªå§çš„å‰å‡ åé¡µçš„å¸–å­æ ‡é¢˜åŠå›å¤å‘½åä¸ºæ ‡é¢˜.txt ä¿å­˜å†…å®¹ä¸ºä¸€å›å¤åŠ ä¸€ä¸ªæ¢è¡Œ  ä»£ç é‡ï¼š23è¡Œ
```python
from L_SPIDER import SPIDER
import re
import urllib.parse
import multiprocessing as mp

k_aim = re.compile('''errer" href="((?:(?:.).*?))" title="(?:(?:.).*?)"''')
k_aim_deep= r'''j_d_post_content " style="display:;">((?:(?:.).*?))<'''
k_aim_deep_file_name =re.compile(r'''<title>((?:(?:.).*?))</title>''')
tieba = urllib.parse.quote('æŠ—å‹èƒŒé”…')

def run(page):
    b = SPIDER(f'https://tieba.baidu.com/f?kw={tieba}&ie=utf-8&pn={page}',k_aim)
    b.get_html()
    ls = b.get_aim_list()
    b.show_aim_list()
    b.deep_crawl_and_save(k_aim_deep,k_aim_deep_file_name,f_url='https://tieba.baidu.com')

pages = [i for i in range(50,201,50)]
if __name__ == '__main__':
    p = mp.Pool(10)
    rel = p.map(run,pages)
    p.close()
    p.join()
```
****

****
# Some things you maybe want know
****
**you are been ban.respect~**<br>
****
![hope_you_luck](https://github.com/LOVEMOSTISBUG/another_files/blob/main/hope_you_luck.png)  
****
**web server was boom.respect~**<br>
****
![bad news](https://github.com/LOVEMOSTISBUG/another_files/blob/main/bad_news.png)  
****
