# L_SPIDER
****
A spider with some methods that been used to crawling data like news and title or pic ,and another things which not encode in  Complex algorithmï¼ˆwell,the truth is i do not learn about it ,if someday i got it ,a new spider will been creat ,i promise.ï¼‰<br>
At very first i code this just for help my friend to finish thier subject , and by the way training my programing capacity<br>.
But more i try to improve and perfect ,more i astounded about pentent ablity of SPIDER.<br>
_Excellent data killerï¼Œyou can analyse anything by useing magic algorithm and your favourite programing language with the huge data you crawled by spider if web server allow.ğŸ˜ˆ_<br>
Why i don't use scrapy or another frame? very simple,caused easy task need no Rocket Launcherï¼Œisn't it? <br>
In other words, I want to make a wheel to play by myself.<br>
Wish my code would help you to save some worry like i assisted my friends,good luck with you,guy.ğŸ˜‡<br>
                                                                                                                                            __LOVEMOSTISBUG__<br>
è¿™æ˜¯ä¸€ä¸ªç”¨æ¥æŠ“å–æ•°æ®ï¼Œæ¯”å¦‚æ–°é—»ã€æ ‡é¢˜æˆ–å›¾ç‰‡ï¼Œè¿˜æœ‰ä¸€äº›æ²¡æœ‰ç”¨å¤æ‚çš„ç®—æ³•è¿›è¡Œç¼–ç çš„æ•°æ®çš„***å°çˆ¬è™«***ï¼ˆå¥½å§ï¼Œå…¶å®æ˜¯å°å¼Ÿ**å­¦ä¸šä¸ç²¾**ï¼Œå“ªå¤©æˆ‘æ‡‚äº†ï¼Œä¼šæŠŠè¯¥æœ‰çš„éƒ½åŠ ä¸Šå»çš„ï¼Œä¿è¯ï¼‰ã€‚<br>
ä¸€å¼€å§‹æˆ‘ç¼–å†™è¿™ä¸ªä»£ç åªæ˜¯ä¸ºäº†å¸®æˆ‘çš„æœ‹å‹å®Œæˆä»–ä»¬çš„è¯¾é¢˜ï¼Œé¡ºä¾¿è®­ç»ƒæˆ‘è‡ªå·±çš„ç¼–ç¨‹èƒ½åŠ›ã€‚<br>
ä½†è¶Šæ˜¯åŠ æ²¹æ”¹è¿›å’Œå®Œå–„ï¼Œå°±è¶ŠæƒŠè®¶äºçˆ¬è™«çš„æ½œèƒ½ã€‚<br>
_ç‰›Xçš„æ•°æ®æ€æ‰‹ï¼Œä½ å¯ä»¥åˆ†æä»»ä½•äº‹ç‰©é€šè¿‡ä½¿ç”¨é­”æœ¯ç®—æ³•å’Œä½ æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€ä¸ä½ çˆ¬ä¸‹æ¥çš„å·¨å¤§æ•°æ®ï¼Œ**å¦‚æœç½‘ç»œæœåŠ¡å™¨å…è®¸**ã€‚ğŸ˜ˆ_<br>
ä¸ºæ¯›æˆ‘ä¸ç”¨Scrapyè¿™æ ·çš„æ¡†æ¶å»çˆ¬ï¼Ÿæ€é¸¡ç„‰ç”¨ç‰›åˆ€ï¼Œä½ è¯´æ˜¯å§~<br>
è¿˜æœ‰çš„è¯å…¶å®æ˜¯æˆ‘ä¹Ÿæƒ³é€ ä¸ªè½®å­è‡ªå·±ç©ï¼ˆå°å£°bbï¼‰<br>
å¸Œæœ›æˆ‘çš„ä»£ç èƒ½å¸®ä½ çœå»ä¸€äº›çƒ¦æ¼ï¼Œå°±åƒæˆ‘å¸®åŠ©æˆ‘çš„æœ‹å‹ä¸€æ ·ï¼Œç¥ä½ å¥½è¿ï¼Œä¼™è®¡ã€‚ğŸ˜‡<br>
                                                                                                                                           __LOVEMOSTISBUG__  <br>
# åœ¨æ•™ç¨‹å¼€å§‹å‰æœ‰ä»¶äº‹å¿…é¡»å¾—å‘Šè¯‰ä½ 
****
**é«˜å¼ºåº¦å’Œæ²¡æœ‰å¾—åˆ°å…è®¸çš„è„šæœ¬è®¿é—®æ˜¯æ‰€æœ‰æœåŠ¡å™¨å›å’Œç½‘ç«™ç®¡ç†å‘˜éƒ½ä¸æƒ³æ¥å¾…çš„ã€‚ã€Šä»å…¥é—¨åˆ°å…¥ç‹±ã€‹ã€‚**<br>
**é«˜å¼ºåº¦å’Œæ²¡æœ‰å¾—åˆ°å…è®¸çš„è„šæœ¬è®¿é—®æ˜¯æ‰€æœ‰æœåŠ¡å™¨å›å’Œç½‘ç«™ç®¡ç†å‘˜éƒ½ä¸æƒ³æ¥å¾…çš„ã€‚ã€Šä»å…¥é—¨åˆ°å…¥ç‹±ã€‹ã€‚**<br>
**é«˜å¼ºåº¦å’Œæ²¡æœ‰å¾—åˆ°å…è®¸çš„è„šæœ¬è®¿é—®æ˜¯æ‰€æœ‰æœåŠ¡å™¨å›å’Œç½‘ç«™ç®¡ç†å‘˜éƒ½ä¸æƒ³æ¥å¾…çš„ã€‚ã€Šä»å…¥é—¨åˆ°å…¥ç‹±ã€‹ã€‚**<br>
**ä»…ä¾›å­¦ä¹ å‚è€ƒã€‚**<br>
****

# How to crawl æ¸¸æˆå¼€å§‹
****
SPIDERè¿™ä¸ªç±»é‡Œçš„å‡½æ•°æˆ‘æ¥è§£é‡Šä¸€ä¸‹å§ã€‚<br>
åˆå§‹å®šä¹‰æ—¶éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯ç›®æ ‡urlè¿˜æœ‰ä¾¿æ˜¯ç›®æ ‡çš„æ­£åˆ™ã€‚<br>
url_openå°±æ˜¯ä¼ªé€ æŠ¥å¤´å’Œä»£ç†IPè®¿é—®URLå¹¶è¿”å›å€¼(é»˜è®¤äºŒè¿›åˆ¶)<br>
get_htmlè®¿é—®æœ¬èº«åœ°å€å¹¶è¿”å›ä¸”ä¿å­˜URL<br>
show_htmlè¾“å‡ºæœ¬èº«åœ°å€HTML<br>
get_aim_listè®¿é—®æœ¬èº«åœ°å€å¹¶è¿”å›ä¸”ä¿å­˜ç›®æ ‡URLåˆ—è¡¨<br>
show_aim_listé€ä¸ªè¾“å‡ºç›®æ ‡çš„URL<br>
ä¸€èˆ¬æ˜¯å…ˆç”¨crawlåˆå§‹åŒ–åŸºæœ¬çš„HTMLå’Œç›®æ ‡URLåˆ—è¡¨å½“ç„¶çœ‹ä½ å…·ä½“éœ€æ±‚ï¼Œä»£ç å·²ç»å°½é‡ç®€ç•¥å¥½ä¸æŸå¤±è‡ªç”±åº¦äº†ä¸ªäººè§‰å¾—ã€‚<br>
L_printæ˜¯å› ä¸ºæŸäº›å­—ç¬¦æ— æ³•æ‰“å°å‡ºæ¥åˆä¸æƒ³æŠ¥é”™å†™çš„ç±»ä¼¼printå‡½æ•°<br>
downloadå°±æ˜¯download å‚æ•°æœ‰ç›®æ ‡urlå’Œä¿å­˜åˆ°æ–‡ä»¶å¤¹ï¼Œé»˜è®¤æ˜¯æ ¹ç›®å½•<br>
keep_data_one_pageåªä¿å­˜ä¸€é¡µçš„æ•°æ® å‚æ•°ä¸ºurlå’Œçˆ¬å–ä¸€æ¬¡å¾—åˆ°çš„æ˜¯å…ƒç»„æ—¶çš„åˆ†éš”ç¬¦å·<br>
keep_data_by_pageså‚æ•°ä¸ºçˆ¬å–é¡µæ•° å‰æ®µurlå’Œåæ®µurlï¼ˆä¸­é—´å¤¹ç€é¡µæ•°ï¼‰ è¿˜æœ‰åˆ†éš”ç¬¦å· ä»¥åŠé¡µæ•°è·¨åº¦<br>
deep_crawl é¦–å…ˆæ˜¯æ·±å…¥çˆ¬çš„æ­£åˆ™ è¿˜æœ‰å°±æ˜¯å‰æ®µurlå’Œåæ®µurl<br>
deep_crawl_and_save æ·±å…¥çˆ¬çš„æ­£åˆ™ ä¿å­˜æ–‡ä»¶å¤¹ è¿˜æœ‰å°±æ˜¯å‰æ®µurlå’Œåæ®µurl<br>

## TASK 0 å¦‚æœä½ åªæ˜¯è½»é‡çº§çš„çˆ¬å– <br>æ¯”å¦‚æ¥ä¸‹æ¥çš„çˆ¬å–æ–°é—»ç½‘ç«™å¸¦æœ‰Chineseçš„æ‰€æœ‰æ–°é—»æ ‡é¢˜<br> ä½ ç”šè‡³ä¸éœ€è¦ç”¨åˆ°æˆ‘å†™çš„ç±»<br>ç›´æ¥è¿™æ ·å°±è¡Œ<br>å½“ç„¶ ç”¨æˆ‘çš„ä¹Ÿèƒ½å¾ˆä¸é”™çš„å®Œæˆä»»åŠ¡ ~èƒ½å¸®ä½ å‰©ä¸‹äº›æ—¶é—´å»å¹²å…¶ä»–äº‹æƒ…
```python
import urllib.request
import urllib.parse
import random
import re
import time

def url_open(url):
    my_headers = list(set(open('user_agent.txt','r').read().split('\n')))
    iplist = list(set(open('ip.txt','r').read().split('\n')))
    my_ip = random.choice(iplist)
    my_head = random.choice(my_headers)
    print (my_ip+'\n'+my_head+'\n')
    iplist =list(set(open('ip.txt','r').read().split('\n')))
    proxy_support = urllib.request.ProxyHandler({'http':my_ip})
    opener = urllib.request.build_opener(proxy_support)
    opener.addheaders = [('User-Agent',my_head)]
    urllib.request.install_opener(opener)
    req = urllib.request.Request(url)
    response = urllib.request.urlopen(req)
    html1 = response.read()
    return html1

def gkd(url,k):
    c = re.findall(k,url_open(url).decode('utf-8'))
    c=list(set(c))
    return c

k1 = re.compile(r'class="story-txt">\r\n\t\t\t\t\t\t((?:.).*?)\t\t\t\t\t</div>')
for i in range(1,200):
    url2 = 'https://globalnews.ca/gnca-ajax/search-results/%7B%22term%22:%22china%22,%22type%22:%22news%22,%22page%22:'+str(i)+'%7D/'
    t = gkd(url2,k1)
    for i in t:
        b = str(i).replace('&#039;','\'')
        b = b.replace('&quot;',' ')
        print(b)
        with open ('T.txt','a',encoding="utf-8")as f:
            f.write(b+'\n')
    
print('ok done')

```
****

****
## TASK 1 ç™¾åº¦è´´å§ï¼šæŸå§é¦–æ¨å‰å‡ åé¡µçš„å¸–å­æ ‡é¢˜åŠå›å¤ å‘½åä¸ºæ ‡é¢˜.txt å†™å…¥å†…å®¹ä¸ºä¸€å›å¤åŠ ä¸€æ¢è¡Œ ä¿å­˜åˆ°åŸç›®å½•dataæ–‡ä»¶å¤¹å†… ä»£ç é‡ï¼š23è¡Œ
```python
from L_SPIDER import SPIDER
import re
import urllib.parse
import multiprocessing as mp

k_aim = re.compile('''errer" href="((?:(?:.).*?))" title="(?:(?:.).*?)"''')
k_aim_deep= r'''j_d_post_content " style="display:;">((?:(?:.).*?))<'''
k_aim_deep_file_name =re.compile(r'''<title>((?:(?:.).*?))</title>''')
tieba = urllib.parse.quote('æŠ—å‹èƒŒé”…')
page = 50
b = SPIDER(f'https://tieba.baidu.com/f?kw={tieba}&ie=utf-8&pn={str(page)}',k_aim)
b.get_html()
ls = b.get_aim_list()
b.show_aim_list()
def run(urls):
    b.deep_crawl_and_save(k_aim_deep,k_aim_deep_file_name,f_url='https://tieba.baidu.com')

if __name__ == '__main__':
    p = mp.Pool(10)
    rel = p.map(run,ls)
    p.close()
    p.join()
```
****
å¤šçº¿ç¨‹ä¸‹ï¼Œçˆ¬å–éå¸¸è¿…é€Ÿï¼Œ5så†…3000æ•°æ®åº”è¯¥é—®é¢˜ä¸å¤§ï¼Œå¯¹è¯¾é¢˜æˆ–è€…å»ºç«‹ä»€ä¹ˆæ¨¡å‹åŸºæœ¬å°±èƒ½å¤Ÿå¼€å§‹äº†ã€‚<br>
æ­£åˆ™è¡¨è¾¾å¼å¦‚æœä¸ä¼šå†™å¯ä»¥ç”¨è¿™æ‹›ã€‚æŠŠå‰é¢çš„ç‰¹å¾å’Œåé¢çš„ç‰¹å¾æ¢æˆä½ å¯¹åº”çš„å†…å®¹å‰åç‰¹å¾ä¾¿æ˜¯ã€‚<br>
```python
k_aim = re.compile('''å‰é¢çš„ç‰¹å¾((?:(?:.).*?))åé¢çš„ç‰¹å¾''')
```
emmmæˆ‘è§‰å¾—éƒ½æ¥çˆ¬è™«äº†æ–‡æœ¬æ“ä½œä»€ä¹ˆçš„åº”è¯¥éƒ½ä¼šäº†å§æ‰€ä»¥ä¸å¤šè¯´äº†ã€‚<br>
å…¶ä¸­æ•ˆæœå¦‚ä¸‹ï¼š
****
![hope_you_luck](https://github.com/LOVEMOSTISBUG/another_files/blob/main/tieba0.PNG)  
****

****

# Some things you maybe want know
****
**you are been ban.respect~**<br>
****
![hope_you_luck](https://github.com/LOVEMOSTISBUG/another_files/blob/main/hope_you_luck.png)  
****
**web server was boom.respect~**<br>
****
![bad news](https://github.com/LOVEMOSTISBUG/another_files/blob/main/bad_news.png)  
****
